Policy Gradient Methods
Environment Simulator Used : OpenAI Gym.
Minimal Install
1)git clone https://github.com/openai/gym
2)cd gym
3)pip install -e . # minimal install

All methods use softmax parametrization
1)Monte Carlo Policy Gradient : Baseline used is average of rewards obtained, no baseline results in high variance
2)Actor Critic Method : 
3)Numerical Gradient Estimation : perturb the parameters and estimate the gradient using regression (X'X)^-1X'y. 
Change num_rollouts to change the number of training examples we learn the gradient from.
Note that the actual number of runs is number of episodes*num_rollouts



